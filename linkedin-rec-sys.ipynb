{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6183ea25",
   "metadata": {},
   "source": [
    "# LinkedIn Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e665945",
   "metadata": {},
   "source": [
    "## Dataset download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130985f1",
   "metadata": {},
   "source": [
    "This project uses the **‚Äú1.3M LinkedIn Jobs and Skills 2024‚Äù** dataset available on [Kaggle](https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024).\n",
    "\n",
    "The dataset contains over **1.3 million LinkedIn job postings** collected in 2024, including detailed information on job titles, descriptions, companies, and associated skills. It is used to train and evaluate our job recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187ec7d4",
   "metadata": {},
   "source": [
    "### Download Options\n",
    "\n",
    "You can obtain the dataset in two ways:\n",
    "\n",
    "1. **Using the Kaggle API (Recommended)** ‚Äî automatic download and extraction.  \n",
    "2. **Manual Download** ‚Äî download the ZIP file directly from the dataset page and extract it yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b88a8e2",
   "metadata": {},
   "source": [
    "### Option 1 ‚Äî Using the Kaggle API\n",
    "\n",
    "To use the Kaggle API, ensure you have the Kaggle CLI installed and configured.\n",
    "\n",
    "```bash\n",
    "# Install Kaggle CLI\n",
    "pip install kaggle\n",
    "\n",
    "# Move your Kaggle API key (kaggle.json) into place\n",
    "mkdir -p ~/.kaggle\n",
    "mv ~/Downloads/kaggle.json ~/.kaggle/\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "```\n",
    "\n",
    "Once configured, you can run the provided script to automatically download and unzip the dataset into the `data/` folder.\n",
    "\n",
    "```bash\n",
    "chmod +x ./download_linkedin_dataset.sh\n",
    "./download_linkedin_dataset.sh\n",
    "```\n",
    "\n",
    "This script:\n",
    "- Creates the `data/` folder if it does not exist.\n",
    "- Downloads the dataset from Kaggle.\n",
    "- Extracts the contents.\n",
    "- Removes the ZIP file after extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a700fb",
   "metadata": {},
   "source": [
    "### Option 2 ‚Äî Manual Download\n",
    "\n",
    "If you prefer not to use the Kaggle API, you can manually download the dataset from:\n",
    "\n",
    "üîó **[https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024](https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024)**\n",
    "\n",
    "After downloading:\n",
    "1. Extract the ZIP file.  \n",
    "2. Move all extracted files into the `data/` directory in your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66ddf2c",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Ensure your Kaggle API credentials (`kaggle.json`) are correctly configured in `~/.kaggle/`.\n",
    "- The dataset is distributed under the **ODC Attribution License (ODC-By)**.\n",
    "- The total size is ~2 Gb (~1.3M entries), so the download may take several minutes depending on your connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787fe36f",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a7fbf2",
   "metadata": {},
   "source": [
    "### Load and Inner Join\n",
    "\n",
    "We load two CSVs:\n",
    "\n",
    "- `job_postings_df` from `./data/linkedin_job_postings.csv`\n",
    "- `job_summary_df` from `./data/job_summary.csv`\n",
    "- `job_skills_df` from `./data/job_skills.csv`\n",
    "\n",
    "We then **inner join** on the unique key `job_link`:\n",
    "\n",
    "- `jobs_df = pd.merge(job_postings_df, job_skills_df, on=\"job_link\", how=\"inner\")`\n",
    "- `jobs_df = pd.merge(jobs_df, job_summary_df, on=\"job_link\", how=\"inner\")`\n",
    "\n",
    "This keeps only postings that exist in every sources and ensures aligned rows across tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7a45a6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:19.769092Z",
     "start_time": "2025-11-30T21:47:42.704288Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "job_skills_df = pd.read_csv('./data/job_skills.csv')\n",
    "job_summary_df = pd.read_csv('./data/job_summary.csv')\n",
    "job_postings_df = pd.read_csv('./data/linkedin_job_postings.csv')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "8ffe467d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:19.779566Z",
     "start_time": "2025-11-30T21:48:19.774167Z"
    }
   },
   "source": [
    "job_skills_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/housekeeper...   \n",
       "1  https://www.linkedin.com/jobs/view/assistant-g...   \n",
       "2  https://www.linkedin.com/jobs/view/school-base...   \n",
       "3  https://www.linkedin.com/jobs/view/electrical-...   \n",
       "4  https://www.linkedin.com/jobs/view/electrical-...   \n",
       "\n",
       "                                          job_skills  \n",
       "0  Building Custodial Services, Cleaning, Janitor...  \n",
       "1  Customer service, Restaurant management, Food ...  \n",
       "2  Applied Behavior Analysis (ABA), Data analysis...  \n",
       "3  Electrical Engineering, Project Controls, Sche...  \n",
       "4  Electrical Assembly, Point to point wiring, St...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/housekeeper...</td>\n",
       "      <td>Building Custodial Services, Cleaning, Janitor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/assistant-g...</td>\n",
       "      <td>Customer service, Restaurant management, Food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/school-base...</td>\n",
       "      <td>Applied Behavior Analysis (ABA), Data analysis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/electrical-...</td>\n",
       "      <td>Electrical Engineering, Project Controls, Sche...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/electrical-...</td>\n",
       "      <td>Electrical Assembly, Point to point wiring, St...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "54a38949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:19.849127Z",
     "start_time": "2025-11-30T21:48:19.846670Z"
    }
   },
   "source": "job_summary_df.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/restaurant-...   \n",
       "1  https://www.linkedin.com/jobs/view/med-surg-re...   \n",
       "2  https://www.linkedin.com/jobs/view/registered-...   \n",
       "3  https://uk.linkedin.com/jobs/view/commercial-a...   \n",
       "4  https://www.linkedin.com/jobs/view/store-manag...   \n",
       "\n",
       "                                         job_summary  \n",
       "0  Rock N Roll Sushi is hiring a Restaurant Manag...  \n",
       "1  Schedule\\n: PRN is required minimum 12 hours p...  \n",
       "2  Description\\nIntroduction\\nAre you looking for...  \n",
       "3  Commercial account executive\\nSheffield\\nFull ...  \n",
       "4  Address:\\nUSA-CT-Newington-44 Fenn Road\\nStore...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/restaurant-...</td>\n",
       "      <td>Rock N Roll Sushi is hiring a Restaurant Manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/med-surg-re...</td>\n",
       "      <td>Schedule\\n: PRN is required minimum 12 hours p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/registered-...</td>\n",
       "      <td>Description\\nIntroduction\\nAre you looking for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://uk.linkedin.com/jobs/view/commercial-a...</td>\n",
       "      <td>Commercial account executive\\nSheffield\\nFull ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/store-manag...</td>\n",
       "      <td>Address:\\nUSA-CT-Newington-44 Fenn Road\\nStore...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "a08cb07a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:19.871472Z",
     "start_time": "2025-11-30T21:48:19.867861Z"
    }
   },
   "source": [
    "job_postings_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/account-exe...   \n",
       "1  https://www.linkedin.com/jobs/view/registered-...   \n",
       "2  https://www.linkedin.com/jobs/view/restaurant-...   \n",
       "3  https://www.linkedin.com/jobs/view/independent...   \n",
       "4  https://www.linkedin.com/jobs/view/group-unit-...   \n",
       "\n",
       "             last_processed_time got_summary got_ner is_being_worked  \\\n",
       "0   2024-01-21 07:12:29.00256+00           t       t               f   \n",
       "1   2024-01-21 07:39:58.88137+00           t       t               f   \n",
       "2  2024-01-21 07:40:00.251126+00           t       t               f   \n",
       "3  2024-01-21 07:40:00.308133+00           t       t               f   \n",
       "4  2024-01-19 09:45:09.215838+00           f       f               f   \n",
       "\n",
       "                                           job_title  \\\n",
       "0  Account Executive - Dispensing (NorCal/Norther...   \n",
       "1                 Registered Nurse - RN Care Manager   \n",
       "2               RESTAURANT SUPERVISOR - THE FORKLIFT   \n",
       "3                      Independent Real Estate Agent   \n",
       "4  Group/Unit Supervisor (Systems Support Manager...   \n",
       "\n",
       "                        company          job_location  first_seen  \\\n",
       "0                            BD         San Diego, CA  2024-01-15   \n",
       "1             Trinity Health MI     Norton Shores, MI  2024-01-14   \n",
       "2       Wasatch Adaptive Sports             Sandy, UT  2024-01-14   \n",
       "3    Howard Hanna | Rand Realty  Englewood Cliffs, NJ  2024-01-16   \n",
       "4  IRS, Office of Chief Counsel          Chamblee, GA  2024-01-17   \n",
       "\n",
       "   search_city search_country                       search_position  \\\n",
       "0     Coronado  United States                           Color Maker   \n",
       "1  Grand Haven  United States              Director Nursing Service   \n",
       "2       Tooele  United States                              Stand-In   \n",
       "3    Pinehurst  United States                     Real-Estate Clerk   \n",
       "4      Gadsden  United States  Supervisor Travel-Information Center   \n",
       "\n",
       "    job_level job_type  \n",
       "0  Mid senior   Onsite  \n",
       "1  Mid senior   Onsite  \n",
       "2  Mid senior   Onsite  \n",
       "3  Mid senior   Onsite  \n",
       "4  Mid senior   Onsite  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/account-exe...</td>\n",
       "      <td>2024-01-21 07:12:29.00256+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Account Executive - Dispensing (NorCal/Norther...</td>\n",
       "      <td>BD</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>2024-01-15</td>\n",
       "      <td>Coronado</td>\n",
       "      <td>United States</td>\n",
       "      <td>Color Maker</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/registered-...</td>\n",
       "      <td>2024-01-21 07:39:58.88137+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Registered Nurse - RN Care Manager</td>\n",
       "      <td>Trinity Health MI</td>\n",
       "      <td>Norton Shores, MI</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>Grand Haven</td>\n",
       "      <td>United States</td>\n",
       "      <td>Director Nursing Service</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/restaurant-...</td>\n",
       "      <td>2024-01-21 07:40:00.251126+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>RESTAURANT SUPERVISOR - THE FORKLIFT</td>\n",
       "      <td>Wasatch Adaptive Sports</td>\n",
       "      <td>Sandy, UT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>Tooele</td>\n",
       "      <td>United States</td>\n",
       "      <td>Stand-In</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/independent...</td>\n",
       "      <td>2024-01-21 07:40:00.308133+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Independent Real Estate Agent</td>\n",
       "      <td>Howard Hanna | Rand Realty</td>\n",
       "      <td>Englewood Cliffs, NJ</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>Pinehurst</td>\n",
       "      <td>United States</td>\n",
       "      <td>Real-Estate Clerk</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/group-unit-...</td>\n",
       "      <td>2024-01-19 09:45:09.215838+00</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Group/Unit Supervisor (Systems Support Manager...</td>\n",
       "      <td>IRS, Office of Chief Counsel</td>\n",
       "      <td>Chamblee, GA</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>Gadsden</td>\n",
       "      <td>United States</td>\n",
       "      <td>Supervisor Travel-Information Center</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "114c2b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:21.544441Z",
     "start_time": "2025-11-30T21:48:19.931350Z"
    }
   },
   "source": [
    "jobs_df = pd.merge(job_postings_df, job_skills_df, on='job_link', how='inner')\n",
    "jobs_df = pd.merge(jobs_df, job_summary_df, on='job_link', how='inner')"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "8f210cc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:26.269649Z",
     "start_time": "2025-11-30T21:48:21.568719Z"
    }
   },
   "source": [
    "jobs_df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 job_link  \\\n",
       "count                                             1296381   \n",
       "unique                                            1296381   \n",
       "top     https://www.linkedin.com/jobs/view/account-exe...   \n",
       "freq                                                    1   \n",
       "\n",
       "                  last_processed_time got_summary  got_ner is_being_worked  \\\n",
       "count                         1296381     1296381  1296381         1296381   \n",
       "unique                         722728           1        1               1   \n",
       "top     2024-01-19 09:45:09.215838+00           t        t               f   \n",
       "freq                           573487     1296381  1296381         1296381   \n",
       "\n",
       "                      job_title          company  job_location  first_seen  \\\n",
       "count                   1296381          1296372       1296362     1296381   \n",
       "unique                   565695            88995         28791           6   \n",
       "top     LEAD SALES ASSOCIATE-FT  Health eCareers  New York, NY  2024-01-14   \n",
       "freq                       7315            40049         12580      459354   \n",
       "\n",
       "           search_city search_country    search_position   job_level job_type  \\\n",
       "count          1296381        1296381            1296381     1296381  1296381   \n",
       "unique            1018              4               1923           2        3   \n",
       "top     North Carolina  United States  Account Executive  Mid senior   Onsite   \n",
       "freq              9495        1105410              19465     1155276  1285565   \n",
       "\n",
       "                                               job_skills  \\\n",
       "count                                             1294296   \n",
       "unique                                            1287101   \n",
       "top     Front Counter, DriveThru, Outside Order Taker,...   \n",
       "freq                                                  169   \n",
       "\n",
       "                                              job_summary  \n",
       "count                                             1296381  \n",
       "unique                                             957570  \n",
       "top     Dollar General Corporation has been delivering...  \n",
       "freq                                                 4565  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296372</td>\n",
       "      <td>1296362</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1294296</td>\n",
       "      <td>1296381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1296381</td>\n",
       "      <td>722728</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>565695</td>\n",
       "      <td>88995</td>\n",
       "      <td>28791</td>\n",
       "      <td>6</td>\n",
       "      <td>1018</td>\n",
       "      <td>4</td>\n",
       "      <td>1923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1287101</td>\n",
       "      <td>957570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/account-exe...</td>\n",
       "      <td>2024-01-19 09:45:09.215838+00</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>LEAD SALES ASSOCIATE-FT</td>\n",
       "      <td>Health eCareers</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>United States</td>\n",
       "      <td>Account Executive</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Front Counter, DriveThru, Outside Order Taker,...</td>\n",
       "      <td>Dollar General Corporation has been delivering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>573487</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>1296381</td>\n",
       "      <td>7315</td>\n",
       "      <td>40049</td>\n",
       "      <td>12580</td>\n",
       "      <td>459354</td>\n",
       "      <td>9495</td>\n",
       "      <td>1105410</td>\n",
       "      <td>19465</td>\n",
       "      <td>1155276</td>\n",
       "      <td>1285565</td>\n",
       "      <td>169</td>\n",
       "      <td>4565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9e57040a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:26.287390Z",
     "start_time": "2025-11-30T21:48:26.285984Z"
    }
   },
   "source": [
    "input_cols = [\n",
    "    'job_link',\n",
    "    'job_title',\n",
    "    'job_location',\n",
    "    'search_country',\n",
    "    'job_skills',\n",
    "    'company',\n",
    "    'search_position',\n",
    "    'job_summary',\n",
    "    'job_level',\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "3124aa87",
   "metadata": {},
   "source": [
    "### Row Filtering\n",
    "\n",
    "We remove rows that do not contain the required NLP outputs and rows flagged as in-progress:\n",
    "\n",
    "- Drop entries **without NER** results.\n",
    "- Drop entries **without summary**.\n",
    "- Drop entries where **`is_being_worked` is `True`**.\n",
    "\n",
    "This reduces noise and guarantees each training sample has complete text features."
   ]
  },
  {
   "cell_type": "code",
   "id": "3c8c0336",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:27.265071Z",
     "start_time": "2025-11-30T21:48:26.322910Z"
    }
   },
   "source": [
    "jobs_df = jobs_df.loc[\n",
    "    (jobs_df[\"is_being_worked\"] == \"f\")\n",
    "    & (jobs_df[\"got_summary\"] == \"t\")\n",
    "    & (jobs_df[\"got_ner\"] == \"t\")\n",
    "]\n",
    "\n",
    "jobs_df = jobs_df[input_cols].dropna().reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "b6bd4322",
   "metadata": {},
   "source": [
    "### Title Normalization and Reduction of Unique Values\n",
    "\n",
    "We normalize `job_title` with a custom function:\n",
    "\n",
    "1. **Lowercase** titles.\n",
    "2. **Trim at the first dash**: keep text before `\"-\"` to collapse variants like  \n",
    "   `Senior Software Engineer - Backend` ‚Üí `senior software engineer`.\n",
    "3. **Remove parenthetical fragments**: delete content inside `(...)`, e.g.  \n",
    "   `data scientist (NLP)` ‚Üí `data scientist`.\n",
    "4. **Strip whitespace**.\n",
    "\n",
    "**Effect:** Different textual variants map to a **single canonical form**, which **reduces the number of unique job titles** and stabilizes downstream grouping and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "971b600f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:27.540914Z",
     "start_time": "2025-11-30T21:48:27.272966Z"
    }
   },
   "source": [
    "def _clean_job_titles(job_title: str):\n",
    "    job_title = job_title.lower()\n",
    "    if '-' in job_title:\n",
    "        job_title = job_title.split('-')[0].strip()\n",
    "    job_title = job_title.split('(')[0].strip()\n",
    "    return job_title.strip()\n",
    "\n",
    "jobs_df['job_title'] = jobs_df['job_title'].astype(str).apply(_clean_job_titles)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "763e7be2",
   "metadata": {},
   "source": [
    "### Skill Canonicalization and Reduction of Unique Values\n",
    "\n",
    "We clean `job_skills` as a comma-separated list:\n",
    "\n",
    "1. **Split by comma** and **strip** whitespace.\n",
    "2. **Lowercase** each skill token.\n",
    "3. **De-duplicate per posting** to avoid repeated skills.\n",
    "4. **Sort tokens** so the per-row skill list has a consistent order.\n",
    "\n",
    "We also track a **global set of unique skills** to measure coverage.\n",
    "\n",
    "**Effect:** Canonicalization merges superficial variants and ordering differences, which **reduces both per-row and global unique skill counts**. This yields a more compact and reliable skill space.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d682398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:54.466952Z",
     "start_time": "2025-11-30T21:48:27.543542Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "# create a cleaned list of skills per job and a global unique skills array\n",
    "def _clean_split_skills(skills_str: str):\n",
    "    skills_str = skills_str.lower()\n",
    "    parts = str(skills_str).split(',')\n",
    "    unique = set()\n",
    "    for part in parts:\n",
    "        # remove non A-Za-z characters except whitespace, collapse spaces and strip ends\n",
    "        c = re.sub(r'[^A-Za-z\\s]', '', part)\n",
    "        c = re.sub(r'\\s+', ' ', c).strip()\n",
    "        if c:\n",
    "            unique.add(c)\n",
    "    # return a deterministic, cleaned, ordered string\n",
    "    ordered = sorted(unique)\n",
    "    return ', '.join(ordered)\n",
    "\n",
    "jobs_df['job_skills'] = jobs_df['job_skills'].astype(str).apply(_clean_split_skills)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "0ed0acdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:54.475946Z",
     "start_time": "2025-11-30T21:48:54.472604Z"
    }
   },
   "source": [
    "display(jobs_df.head())"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/account-exe...   \n",
       "1  https://www.linkedin.com/jobs/view/registered-...   \n",
       "2  https://www.linkedin.com/jobs/view/restaurant-...   \n",
       "3  https://www.linkedin.com/jobs/view/independent...   \n",
       "4  https://www.linkedin.com/jobs/view/registered-...   \n",
       "\n",
       "                       job_title          job_location search_country  \\\n",
       "0              account executive         San Diego, CA  United States   \n",
       "1               registered nurse     Norton Shores, MI  United States   \n",
       "2          restaurant supervisor             Sandy, UT  United States   \n",
       "3  independent real estate agent  Englewood Cliffs, NJ  United States   \n",
       "4               registered nurse          Muskegon, MI  United States   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0  bachelors degree, bd offerings, challenges, co...   \n",
       "1  bachelor of science in nursing, care managemen...   \n",
       "2  arithmetic skills, bending and kneeling abilit...   \n",
       "3  closing statements, communication, customer se...   \n",
       "4  bsn, diversity, equal opportunity employer, eq...   \n",
       "\n",
       "                      company           search_position  \\\n",
       "0                          BD               Color Maker   \n",
       "1           Trinity Health MI  Director Nursing Service   \n",
       "2     Wasatch Adaptive Sports                  Stand-In   \n",
       "3  Howard Hanna | Rand Realty         Real-Estate Clerk   \n",
       "4           Trinity Health MI        Nurse Practitioner   \n",
       "\n",
       "                                         job_summary   job_level  \n",
       "0  Responsibilities\\nJob Description Summary\\nJob...  Mid senior  \n",
       "1  Employment Type:\\nFull time\\nShift:\\nDescripti...  Mid senior  \n",
       "2  Job Details\\nDescription\\nWhat You'll Do\\nAs a...  Mid senior  \n",
       "3  Who We Are\\nRand Realty is a family-owned brok...  Mid senior  \n",
       "4  Employment Type:\\nFull time\\nShift:\\n12 Hour N...  Mid senior  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>company</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/account-exe...</td>\n",
       "      <td>account executive</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>United States</td>\n",
       "      <td>bachelors degree, bd offerings, challenges, co...</td>\n",
       "      <td>BD</td>\n",
       "      <td>Color Maker</td>\n",
       "      <td>Responsibilities\\nJob Description Summary\\nJob...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/registered-...</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>Norton Shores, MI</td>\n",
       "      <td>United States</td>\n",
       "      <td>bachelor of science in nursing, care managemen...</td>\n",
       "      <td>Trinity Health MI</td>\n",
       "      <td>Director Nursing Service</td>\n",
       "      <td>Employment Type:\\nFull time\\nShift:\\nDescripti...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/restaurant-...</td>\n",
       "      <td>restaurant supervisor</td>\n",
       "      <td>Sandy, UT</td>\n",
       "      <td>United States</td>\n",
       "      <td>arithmetic skills, bending and kneeling abilit...</td>\n",
       "      <td>Wasatch Adaptive Sports</td>\n",
       "      <td>Stand-In</td>\n",
       "      <td>Job Details\\nDescription\\nWhat You'll Do\\nAs a...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/independent...</td>\n",
       "      <td>independent real estate agent</td>\n",
       "      <td>Englewood Cliffs, NJ</td>\n",
       "      <td>United States</td>\n",
       "      <td>closing statements, communication, customer se...</td>\n",
       "      <td>Howard Hanna | Rand Realty</td>\n",
       "      <td>Real-Estate Clerk</td>\n",
       "      <td>Who We Are\\nRand Realty is a family-owned brok...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/registered-...</td>\n",
       "      <td>registered nurse</td>\n",
       "      <td>Muskegon, MI</td>\n",
       "      <td>United States</td>\n",
       "      <td>bsn, diversity, equal opportunity employer, eq...</td>\n",
       "      <td>Trinity Health MI</td>\n",
       "      <td>Nurse Practitioner</td>\n",
       "      <td>Employment Type:\\nFull time\\nShift:\\n12 Hour N...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "c281aa74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:58.618335Z",
     "start_time": "2025-11-30T21:48:54.493471Z"
    }
   },
   "source": [
    "seen = set()\n",
    "skills_array = []\n",
    "for lst in jobs_df['job_skills']:\n",
    "    for skill in lst.split(','):\n",
    "        skill = skill.strip()\n",
    "        if skill not in seen:\n",
    "            seen.add(skill)\n",
    "            skills_array.append(skill)\n",
    "\n",
    "print(f\"Jobs rows: {len(jobs_df)}, sample job_skills (first 5):\\n\", jobs_df['job_skills'].head())\n",
    "print(f\"Global unique skills count: {len(skills_array)}\")\n",
    "#skills_array[:20]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jobs rows: 1294268, sample job_skills (first 5):\n",
      " 0    bachelors degree, bd offerings, challenges, co...\n",
      "1    bachelor of science in nursing, care managemen...\n",
      "2    arithmetic skills, bending and kneeling abilit...\n",
      "3    closing statements, communication, customer se...\n",
      "4    bsn, diversity, equal opportunity employer, eq...\n",
      "Name: job_skills, dtype: object\n",
      "Global unique skills count: 2668569\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "6affa1e2",
   "metadata": {},
   "source": [
    "### Location Cleaning and Reduction of Unique Values\n",
    "\n",
    "We standardize `job_location` by **keeping only the part before the first comma**:\n",
    "\n",
    "- Example: `San Diego, CA` ‚Üí `San Diego`\n",
    "\n",
    "**Effect:** This collapses formatting variants that differ only by state or country suffix. It **reduces the number of unique locations** and helps counter sparse geography fields while preserving city-level signal."
   ]
  },
  {
   "cell_type": "code",
   "id": "97b513dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:48:59.746431Z",
     "start_time": "2025-11-30T21:48:59.558795Z"
    }
   },
   "source": [
    "def _clean_location(loc: str):\n",
    "    return loc.split(',')[0].strip()\n",
    "\n",
    "jobs_df['job_location'] = jobs_df['job_location'].astype(str).apply(_clean_location)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "8c9a0f8c",
   "metadata": {},
   "source": [
    "## Data Filtering \n",
    "The clean dataset is composed of 1.294.268 jobs posts. For simplification, we focus on the city with the most number of jobs posts (New York)"
   ]
  },
  {
   "cell_type": "code",
   "id": "06d8b962",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:00.690398Z",
     "start_time": "2025-11-30T21:49:00.688456Z"
    }
   },
   "source": [
    "jobs_df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1294268, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "8ca62912",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:02.627533Z",
     "start_time": "2025-11-30T21:49:02.560892Z"
    }
   },
   "source": [
    "jobs_df['job_location'].value_counts()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_location\n",
       "New York         14850\n",
       "London           11551\n",
       "Houston          10380\n",
       "Chicago          10154\n",
       "Los Angeles       9724\n",
       "                 ...  \n",
       "Mathern              1\n",
       "Hurdle Mills         1\n",
       "Haylands             1\n",
       "Kirribilli           1\n",
       "Yallabatharra        1\n",
       "Name: count, Length: 21036, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "9ce9bbdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:02.786371Z",
     "start_time": "2025-11-30T21:49:02.784964Z"
    }
   },
   "source": [
    "##this is in case we want to filter by a different method, filtering the dataset by a threshold of posts.\n",
    "\n",
    "# min_jobs = 100      \n",
    "# max_jobs = 500   \n",
    "\n",
    "# jobs_df = (\n",
    "#     jobs_df\n",
    "#     .groupby(['search_country', 'job_location'])\n",
    "#     .filter(lambda x: len(x) >= min_jobs)  \n",
    "#     .groupby(['search_country', 'job_location'], group_keys=False)\n",
    "#     .apply(lambda x: x.sample(n=min(len(x), max_jobs), random_state=42))\n",
    "# ).reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "dc5788dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:02.966519Z",
     "start_time": "2025-11-30T21:49:02.803483Z"
    }
   },
   "source": [
    "jobs_df = jobs_df[jobs_df['job_location'] == 'New York'].reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "e69c11ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:02.999386Z",
     "start_time": "2025-11-30T21:49:02.971303Z"
    }
   },
   "source": [
    "jobs_df.describe()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 job_link  \\\n",
       "count                                               14850   \n",
       "unique                                              14850   \n",
       "top     https://www.linkedin.com/jobs/view/part-time-h...   \n",
       "freq                                                    1   \n",
       "\n",
       "                  job_title job_location search_country  \\\n",
       "count                 14850        14850          14850   \n",
       "unique                 8822            1              2   \n",
       "top     executive assistant     New York  United States   \n",
       "freq                    174        14850          14849   \n",
       "\n",
       "                                               job_skills  company  \\\n",
       "count                                               14850    14850   \n",
       "unique                                              14842     4032   \n",
       "top     background check, csea tuition vouchers, envir...  DocCafe   \n",
       "freq                                                    2      218   \n",
       "\n",
       "          search_position                                        job_summary  \\\n",
       "count               14850                                              14850   \n",
       "unique               1147                                              13817   \n",
       "top     Account Executive  AC-Full E2E Rule Based Multiplexing Test - Obj...   \n",
       "freq                  402                                                 35   \n",
       "\n",
       "         job_level  \n",
       "count        14850  \n",
       "unique           2  \n",
       "top     Mid senior  \n",
       "freq         12481  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>company</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "      <td>14850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14850</td>\n",
       "      <td>8822</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14842</td>\n",
       "      <td>4032</td>\n",
       "      <td>1147</td>\n",
       "      <td>13817</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/part-time-h...</td>\n",
       "      <td>executive assistant</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>background check, csea tuition vouchers, envir...</td>\n",
       "      <td>DocCafe</td>\n",
       "      <td>Account Executive</td>\n",
       "      <td>AC-Full E2E Rule Based Multiplexing Test - Obj...</td>\n",
       "      <td>Mid senior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>14850</td>\n",
       "      <td>14849</td>\n",
       "      <td>2</td>\n",
       "      <td>218</td>\n",
       "      <td>402</td>\n",
       "      <td>35</td>\n",
       "      <td>12481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "a55e1964",
   "metadata": {},
   "source": [
    "### Feature Set Used\n",
    "\n",
    "After preprocessing, the working DataFrame includes the key fields required for analysis and modeling:\n",
    "\n",
    "- `job_link` (primary key, post-join)\n",
    "- `job_title` (normalized)\n",
    "- `job_location` (city-only normalized)\n",
    "- `search_country`\n",
    "- `job_skills` (cleaned, sorted, de-duplicated)\n",
    "- `job_description`\n",
    "- `search_position`\n",
    "- `job_level`\n",
    "\n",
    "These fields form the basis for representation building and recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d40ee6a",
   "metadata": {},
   "source": [
    "### Impact on Cardinality (Unique Values)\n",
    "\n",
    "The following transformations are specifically designed to **reduce the number of unique values**:\n",
    "\n",
    "- **Job titles:** lowercasing, dash-trim, and parenthesis removal collapse stylistic variants.\n",
    "- **Skills:** lowercase normalization, de-duplication, and sorted lists produce canonical rows and reduce global skill vocabulary.\n",
    "- **Locations:** truncation before the first comma unifies location strings.\n",
    "\n",
    "This cardinality reduction improves:\n",
    "- Statistical reliability of counts and co-occurrences.\n",
    "- Memory usage and runtime.\n",
    "- Model stability and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de581c",
   "metadata": {},
   "source": [
    "# Content-Based Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6be9e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:03.966844Z",
     "start_time": "2025-11-30T21:49:03.949065Z"
    }
   },
   "source": [
    "#unique number of skills\n",
    "jobs_df[\"job_skills\"].nunique()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "7797f1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:04.747695Z",
     "start_time": "2025-11-30T21:49:03.979821Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "f3727926",
   "metadata": {},
   "source": [
    "In order to build a content-based recommendation system, the dataset must first undergo preprocessing. This is especially important because the dataset is large, and unprocessed text can make computation slow and expensive.\n",
    "Since the dataset contains 14.842 unique skills, many of them appear only a few times. As a first step, we remove rare skills that appear fewer than 10 times, reducing noise and improving the quality of the TF-IDF representations."
   ]
  },
  {
   "cell_type": "code",
   "id": "ae4a4fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:04.751701Z",
     "start_time": "2025-11-30T21:49:04.750366Z"
    }
   },
   "source": [
    "rare_skill_threshold = 10"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "0ed9639d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:05.813335Z",
     "start_time": "2025-11-30T21:49:05.699902Z"
    }
   },
   "source": [
    "def remove_rare_skills(jobs_df, rare_skill_threshold):\n",
    "    # Flatten all skills and strip spaces\n",
    "    all_skills = [s.strip() for skills in jobs_df['job_skills'] for s in skills.split(',')]\n",
    "    \n",
    "    # Count frequency\n",
    "    skill_counts = Counter(all_skills)\n",
    "    \n",
    "    # Identify rare skills\n",
    "    rare_skills = {skill for skill, count in skill_counts.items() if count <= rare_skill_threshold}\n",
    "    \n",
    "    # Remove rare skills from each job\n",
    "    def filter_skills(skills_str):\n",
    "        skills = [s.strip() for s in skills_str.split(',')]\n",
    "        skills = [s for s in skills if s not in rare_skills]\n",
    "        return ', '.join(skills)\n",
    "    \n",
    "    jobs_df['job_skills'] = jobs_df['job_skills'].apply(filter_skills)\n",
    "    # Remove jobs with no skills left\n",
    "    jobs_df = jobs_df[jobs_df['job_skills'].str.strip() != ''].reset_index(drop=True)\n",
    "    return jobs_df\n",
    "\n",
    "jobs_df = remove_rare_skills(jobs_df, rare_skill_threshold)\n",
    "jobs_df.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14767, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "225c7827",
   "metadata": {},
   "source": [
    "As the next step, we preprocess the data to prepare it for vectorization. Since our goal is to recommend jobs based on a user's title and skills, we combine these two fields into a single text input. This merged representation allows the TF-IDF vectorizer to capture the full semantic context of both the job title and its associated skills."
   ]
  },
  {
   "cell_type": "code",
   "id": "3eb9e215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:06.768532Z",
     "start_time": "2025-11-30T21:49:06.764189Z"
    }
   },
   "source": [
    "def preprocess(df):\n",
    "    df['title_skills'] = df['job_title'] + \" \" + df['job_skills']\n",
    "    return df\n",
    "jobs_df = preprocess(jobs_df)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "6236d0cd",
   "metadata": {},
   "source": [
    "Finally, we are ready to create the TF-IDF representation. At this stage, we select the `min_df` and `max_df` parameters, which determine how frequently a term must appear to be included in the vocabulary.\n",
    "\n",
    "`min_df` filters out terms that appear too rarely.\n",
    "\n",
    "`max_df` filters out terms that appear too frequently.\n",
    "\n",
    "After fitting the vectorizer, we obtain a TF-IDF matrix of shape (14,767 √ó 526), where each row corresponds to a job post and each column represents a distinct skill."
   ]
  },
  {
   "cell_type": "code",
   "id": "20aa0c11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:07.827069Z",
     "start_time": "2025-11-30T21:49:07.716676Z"
    }
   },
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_features=10000,       \n",
    "            min_df=100,               \n",
    "            max_df=0.8                \n",
    "        )\n",
    "matrix = vectorizer.fit_transform(jobs_df[\"title_skills\"])"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "58a3736f",
   "metadata": {},
   "source": [
    "Once we have the TF-IDF matrix, we can generate job recommendations based on a user‚Äôs title and skills. The user provides a job title of interest along with a list of skills they possess. The algorithm concatenates these inputs into a single text string and uses the vectorizer‚Äôs transform function to convert it into a TF-IDF vector.\n",
    "We then compute cosine similarity between the user‚Äôs vector and all job posts in the dataset. Finally, the system selects the top 5 job posts with the highest similarity scores, returning the most relevant recommendations."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:08.781884Z",
     "start_time": "2025-11-30T21:49:08.779072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_input(title, skills):\n",
    "    input_title_skills = title + \" \" + \", \".join(skills)\n",
    "    return input_title_skills\n",
    "\n",
    "def fit_input_tfidf(vectorizer, input_title_skills):\n",
    "    input_vec = vectorizer.transform([input_title_skills])\n",
    "    return input_vec\n",
    "\n",
    "def print_recommendations(recommended_jobs, columns=None):\n",
    "    if columns is None:\n",
    "        columns = ['company', 'job_title', 'job_skills', 'job_location']\n",
    "    print(\"Recommended jobs:\")\n",
    "    display(recommended_jobs[columns])\n",
    "\n",
    "def recommend(df, query, vectorizer, matrix, top_k=5, return_scores=False):\n",
    "    input_title_skills = preprocess_input(query['title'], query['skills'])\n",
    "    input_vec = fit_input_tfidf(vectorizer, input_title_skills)\n",
    "\n",
    "    # Filter by city, fallback to country\n",
    "    jobs_to_search = df[df['job_location'] == query['city']].index.to_list()\n",
    "    if len(jobs_to_search) < 2:\n",
    "        jobs_to_search = df[df['search_country'] == query['country']].index.to_list()\n",
    "\n",
    "    matrix_subset = matrix[jobs_to_search]\n",
    "    cos_scores = cosine_similarity(input_vec, matrix_subset).flatten()\n",
    "    top_indices_in_subset = cos_scores.argsort()[::-1][:top_k]\n",
    "    similar_indices = [jobs_to_search[i] for i in top_indices_in_subset]\n",
    "    recommended_jobs = df.iloc[similar_indices].copy()\n",
    "\n",
    "    # Add skills_score if we needed\n",
    "    if return_scores:\n",
    "        recommended_jobs[\"skills_score\"] = cos_scores[top_indices_in_subset]\n",
    "        return recommended_jobs.reset_index(drop=True)\n",
    "\n",
    "    print_recommendations(recommended_jobs)\n",
    "    return recommended_jobs.reset_index(drop=True)"
   ],
   "id": "539c1761726f3476",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NLP Features Based on the Job Descriptions\n",
    "As our new topic, we use extra NLP features, based on the job descriptions, for the recommendation system.\n",
    "First we import the necessary packages."
   ],
   "id": "703f894b318981a8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:09.807842Z",
     "start_time": "2025-11-30T21:49:09.730449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from scipy.sparse import csr_matrix, issparse"
   ],
   "id": "e61407b2262a70b7",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next we create a class, which recommends jobs based only on the job descriptions.\n",
    "Topics used inside the recommender:\n",
    "- TF-IDF with n-grams\n",
    "- Latent Semantic Analysis (LSA) via TruncatedSVD\n",
    "- Topic modelling via NMF\n",
    "- Rocchio pseudo-relevance feedback for query expansion\n",
    "- Combines lexical, LSA and topic similarities into one score"
   ],
   "id": "b1b698bee05e3bc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:10.747244Z",
     "start_time": "2025-11-30T21:49:10.740252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextRecommender:\n",
    "    \"\"\"\n",
    "    Job-description based recommender.\n",
    "\n",
    "    It builds three representations of each job posting:\n",
    "      1. Lexical similarity: TF-IDF with n-grams\n",
    "      2. Low-dimensional semantic space: Latent Semantic Analysis (LSA) via TruncatedSVD\n",
    "      3. Topics: Topic modelling via NMF\n",
    "      4. Optional Rocchio pseudo-relevance feedback\n",
    "\n",
    "    It computes similarities in all three\n",
    "    spaces and combines them into a single score.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        jobs_df,\n",
    "        title_col=\"job_title\",\n",
    "        desc_col=\"job_summary\",\n",
    "        skills_col=None,\n",
    "        min_df=5,\n",
    "        max_df=0.9,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=\"english\",\n",
    "        n_lsa_components=150,\n",
    "        n_topics=20,\n",
    "        random_state=42,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        jobs_df : pd.DataFrame\n",
    "            DataFrame containing job postings.\n",
    "        title_col : str\n",
    "            Column name for the job title text.\n",
    "        desc_col : str\n",
    "            Column name for the job description / summary text.\n",
    "        skills_col : str or None\n",
    "            Optional column name for skills text to append.\n",
    "        min_df, max_df, ngram_range, stop_words :\n",
    "            TF-IDF hyperparameters.\n",
    "        n_lsa_components : int\n",
    "            Number of latent dimensions for LSA.\n",
    "        n_topics : int\n",
    "            Number of topics for NMF.\n",
    "        random_state : int\n",
    "            Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "\n",
    "        # Store a clean copy of the input data\n",
    "        self.jobs_df = jobs_df.copy().reset_index(drop=True)\n",
    "        self.title_col = title_col\n",
    "        self.desc_col = desc_col\n",
    "        self.skills_col = skills_col\n",
    "\n",
    "        # Basic sanity check: make sure required columns exist\n",
    "        required_cols = [title_col, desc_col]\n",
    "        if skills_col is not None:\n",
    "            required_cols.append(skills_col)\n",
    "\n",
    "        missing = [c for c in required_cols if c not in self.jobs_df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(\n",
    "                f\"Missing required columns in jobs_df: {missing}\"\n",
    "            )\n",
    "\n",
    "        # Build a single text field per job: title + description (+ skills)\n",
    "        #    - Replace NaNs with empty strings\n",
    "        #    - Cast to string to avoid problems in TfidfVectorizer\n",
    "        title_text = self.jobs_df[title_col].fillna(\"\").astype(str)\n",
    "        desc_text = self.jobs_df[desc_col].fillna(\"\").astype(str)\n",
    "\n",
    "        if skills_col is not None:\n",
    "            skills_text = self.jobs_df[skills_col].fillna(\"\").astype(str)\n",
    "            full_text = title_text + \" \" + desc_text + \" \" + skills_text\n",
    "        else:\n",
    "            full_text = title_text + \" \" + desc_text\n",
    "\n",
    "        # Store the combined text as an internal column\n",
    "        self.jobs_df[\"__full_text__\"] = full_text\n",
    "\n",
    "        # TF-IDF representation for all jobs\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            min_df=min_df,\n",
    "            max_df=max_df,\n",
    "            ngram_range=ngram_range,\n",
    "            stop_words=stop_words,\n",
    "        )\n",
    "\n",
    "        self.job_tfidf = self.vectorizer.fit_transform(\n",
    "            self.jobs_df[\"__full_text__\"].values\n",
    "        )\n",
    "\n",
    "\n",
    "        # LSA representation (low-dimensional dense vectors)\n",
    "        self.svd = TruncatedSVD(\n",
    "            n_components=n_lsa_components,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        job_lsa = self.svd.fit_transform(self.job_tfidf)\n",
    "        # L2-normalize rows\n",
    "        self.job_lsa = normalize(job_lsa)\n",
    "\n",
    "\n",
    "        # Topic representation via NMF\n",
    "        self.nmf = NMF(\n",
    "            n_components=n_topics,\n",
    "            init=\"nndsvd\",\n",
    "            random_state=random_state,\n",
    "            max_iter=300,\n",
    "        )\n",
    "\n",
    "        job_topics = self.nmf.fit_transform(self.job_tfidf)\n",
    "        self.job_topics = normalize(job_topics)  # L2-normalize rows\n",
    "\n",
    "    # Helpers\n",
    "\n",
    "    # Project user text into TF-IDF space\n",
    "    def _tfidf_query(self, user_text: str):\n",
    "        return self.vectorizer.transform([user_text])\n",
    "\n",
    "    # Project a TF-IDF query vector into LSA space\n",
    "    def _lsa_query(self, tfidf_vec):\n",
    "        q_lsa = self.svd.transform(tfidf_vec)\n",
    "        return normalize(q_lsa)\n",
    "\n",
    "    # Project a TF-IDF query vector into topic space (NMF)\n",
    "    def _topic_query(self, tfidf_vec):\n",
    "        q_topics = self.nmf.transform(tfidf_vec)\n",
    "        return normalize(q_topics)\n",
    "\n",
    "    def _rocchio_expand(\n",
    "        self,\n",
    "        query_vec,\n",
    "        alpha=1.0,\n",
    "        beta=0.75,\n",
    "        gamma=0.15,\n",
    "        n_pos=20,\n",
    "        n_neg=10,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Rocchio pseudo-relevance feedback in TF-IDF space.\n",
    "\n",
    "        Uses the current ranking of documents to:\n",
    "          - pull the query closer to top-ranked (pseudo-relevant) jobs\n",
    "          - push it away from bottom-ranked (pseudo-non-relevant) jobs\n",
    "\n",
    "        Parameters follow the standard Rocchio notation:\n",
    "          - alpha: weight of original query\n",
    "          - beta: weight of positive centroid\n",
    "          - gamma: weight of negative centroid\n",
    "        \"\"\"\n",
    "        # Rank documents with the current query\n",
    "        sims = cosine_similarity(query_vec, self.job_tfidf).ravel()\n",
    "        ranked_idx = np.argsort(-sims)\n",
    "\n",
    "        # Select pseudo-relevant and non-relevant sets\n",
    "        n_pos = min(n_pos, len(ranked_idx))\n",
    "        n_neg = min(n_neg, len(ranked_idx)) if n_neg > 0 else 0\n",
    "\n",
    "        pos_idx = ranked_idx[:n_pos]\n",
    "        neg_idx = ranked_idx[-n_neg:] if n_neg > 0 else []\n",
    "\n",
    "        # Compute centroids in TF-IDF space\n",
    "        pos_centroid = self.job_tfidf[pos_idx].mean(axis=0)\n",
    "        pos_centroid = csr_matrix(pos_centroid)\n",
    "\n",
    "        if n_neg > 0:\n",
    "            neg_centroid = self.job_tfidf[neg_idx].mean(axis=0)\n",
    "            neg_centroid = csr_matrix(neg_centroid)\n",
    "        else:\n",
    "            # zero vector of the same dimension\n",
    "            neg_centroid = csr_matrix(query_vec.shape, dtype=query_vec.dtype)\n",
    "\n",
    "        # Rocchio formula:\n",
    "        expanded = (\n",
    "            alpha * query_vec\n",
    "            + beta * pos_centroid\n",
    "            - gamma * neg_centroid\n",
    "        )\n",
    "\n",
    "        # Ensure we work with a CSR sparse matrix\n",
    "        if not issparse(expanded):\n",
    "            expanded = csr_matrix(expanded)\n",
    "\n",
    "        # Clamp negative weights to zero (TF-IDF is non-negative)\n",
    "        data = np.asarray(expanded.data)\n",
    "        data[data < 0] = 0.0\n",
    "        expanded.data[:] = data\n",
    "\n",
    "        return expanded\n",
    "\n",
    "    # Public \"API\"\n",
    "    def recommend_from_text(\n",
    "        self,\n",
    "        user_text,\n",
    "        top_k=20,\n",
    "        use_rocchio=True,\n",
    "        rocchio_params=None,\n",
    "        weights=None,\n",
    "        return_intermediate=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Recommend jobs based on a free-text description of what the user is looking for.\n",
    "\n",
    "        This function takes a natural-language description of the desired job\n",
    "        and scores all jobs using a mix of lexical similarity, LSA and topic similarity.\n",
    "        It can also possibly improve the query using Rocchio pseudo-relevance feedback.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        user_text : str\n",
    "            Free-text description of the job the user is interested in.\n",
    "        top_k : int\n",
    "            How many jobs to return.\n",
    "        use_rocchio : bool\n",
    "            If True, refine the query using Rocchio pseudo-relevance feedback.\n",
    "        rocchio_params : dict or None\n",
    "            Optional Rocchio hyperparameters, e.g.\n",
    "            {'alpha': ..., 'beta': ..., 'gamma': ..., 'n_pos': ..., 'n_neg': ...}.\n",
    "            If None, sensible defaults are used.\n",
    "        weights : dict or None\n",
    "            Weights for combining the different similarity scores, e.g.\n",
    "            {'lexical': 0.5, 'lsa': 0.3, 'topic': 0.2}.\n",
    "            If None, defaults are used.\n",
    "        return_intermediate : bool\n",
    "            If True, also return the individual component scores\n",
    "            ('lexical_score', 'lsa_score', 'topic_score') in the result.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            A slice of jobs_df containing the top-k recommended jobs with an extra\n",
    "            'combined_text_score' column (and, if requested, the component scores),\n",
    "            sorted from most to least relevant.\n",
    "        \"\"\"\n",
    "        if not isinstance(user_text, str) or not user_text.strip():\n",
    "            raise ValueError(\"user_text must be a non-empty string\")\n",
    "\n",
    "        # Project user text into TF-IDF space\n",
    "        q_tfidf = self._tfidf_query(user_text)\n",
    "\n",
    "        # Rocchio expansion\n",
    "        if use_rocchio:\n",
    "            r_params = {\n",
    "                \"alpha\": 1.0,\n",
    "                \"beta\": 0.75,\n",
    "                \"gamma\": 0.15,\n",
    "                \"n_pos\": 20,\n",
    "                \"n_neg\": 10,\n",
    "            }\n",
    "            if rocchio_params is not None:\n",
    "                r_params.update(rocchio_params)\n",
    "\n",
    "            q_tfidf = self._rocchio_expand(\n",
    "                q_tfidf,\n",
    "                alpha=r_params[\"alpha\"],\n",
    "                beta=r_params[\"beta\"],\n",
    "                gamma=r_params[\"gamma\"],\n",
    "                n_pos=r_params[\"n_pos\"],\n",
    "                n_neg=r_params[\"n_neg\"],\n",
    "            )\n",
    "\n",
    "        # Represent query in all three spaces\n",
    "        q_lsa = self._lsa_query(q_tfidf)\n",
    "        q_topics = self._topic_query(q_tfidf)\n",
    "\n",
    "        # Compute cosine similarities in each space\n",
    "        sim_lexical = cosine_similarity(q_tfidf, self.job_tfidf).ravel()\n",
    "        sim_lsa = cosine_similarity(q_lsa, self.job_lsa).ravel()\n",
    "        sim_topic = cosine_similarity(q_topics, self.job_topics).ravel()\n",
    "\n",
    "        # Normalize scores to [0, 1] for stable combination\n",
    "        def _norm(x):\n",
    "            x = np.asarray(x)\n",
    "            if x.max() == x.min():\n",
    "                # Avoid division by zero if all scores are equal\n",
    "                return np.zeros_like(x)\n",
    "            return (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "        sim_lexical_n = _norm(sim_lexical)\n",
    "        sim_lsa_n = _norm(sim_lsa)\n",
    "        sim_topic_n = _norm(sim_topic)\n",
    "\n",
    "        # Combine scores with given weights\n",
    "        if weights is None:\n",
    "            weights = {\"lexical\": 0.3, \"lsa\": 0.3, \"topic\": 0.3}\n",
    "\n",
    "        combined = (\n",
    "            weights[\"lexical\"] * sim_lexical_n\n",
    "            + weights[\"lsa\"] * sim_lsa_n\n",
    "            + weights[\"topic\"] * sim_topic_n\n",
    "        )\n",
    "\n",
    "        # Take top_k jobs by combined score\n",
    "        idx_sorted = np.argsort(-combined)[:top_k]\n",
    "\n",
    "        result = self.jobs_df.iloc[idx_sorted].copy()\n",
    "        result[\"combined_text_score\"] = combined[idx_sorted]\n",
    "\n",
    "        # Optionally expose individual component scores\n",
    "        if return_intermediate:\n",
    "            result[\"lexical_score\"] = sim_lexical_n[idx_sorted]\n",
    "            result[\"lsa_score\"] = sim_lsa_n[idx_sorted]\n",
    "            result[\"topic_score\"] = sim_topic_n[idx_sorted]\n",
    "\n",
    "        return result.reset_index(drop=True)"
   ],
   "id": "7421a69567fd3716",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We create an instance of a text recommender.",
   "id": "ea232035556295e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:54.901053Z",
     "start_time": "2025-11-30T21:49:11.674132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_rec = TextRecommender(\n",
    "    jobs_df=jobs_df,\n",
    "    title_col=\"job_title\",\n",
    "    desc_col=\"job_summary\",\n",
    "    skills_col=\"job_skills\",\n",
    "    min_df=5,\n",
    "    max_df=0.9,\n",
    "    ngram_range=(1, 2),\n",
    "    n_lsa_components=150,\n",
    "    n_topics=20,\n",
    ")"
   ],
   "id": "80f4fff10def6cbf",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we create a function, which combines the two approaches for the recommendation system.",
   "id": "bb22ddb729fe60f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:56.048549Z",
     "start_time": "2025-11-30T21:49:56.045202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hybrid_recommend(\n",
    "    df,\n",
    "    query,\n",
    "    description_text,\n",
    "    vectorizer,\n",
    "    matrix,\n",
    "    text_rec,\n",
    "    top_k=5,\n",
    "    alpha_text=0.75,\n",
    "    alpha_skills=0.25,\n",
    "):\n",
    "    \"\"\"\n",
    "    Hybrid recommender combining:\n",
    "    - traditional title+skills TF-IDF similarity (\"skills_score\")\n",
    "    - description-based NLP similarity from TextRecommender (\"combined_text_score\")\n",
    "    \"\"\"\n",
    "    # Skills-based recommendations\n",
    "    skills_recs = recommend(\n",
    "        df=df,\n",
    "        query=query,\n",
    "        vectorizer=vectorizer,\n",
    "        matrix=matrix,\n",
    "        top_k=top_k * 5,\n",
    "        return_scores=True,\n",
    "    )\n",
    "\n",
    "    # Text-based recommendations\n",
    "    text_recs = text_rec.recommend_from_text(\n",
    "        user_text=description_text,\n",
    "        top_k=top_k * 5,\n",
    "        use_rocchio=True,\n",
    "        return_intermediate=False,\n",
    "    )\n",
    "\n",
    "    # Ensure we have the primary key\n",
    "    if \"job_link\" not in skills_recs.columns or \"job_link\" not in text_recs.columns:\n",
    "        raise KeyError(\"job_link column not found in recommendations; ensure it is kept in jobs_df.\")\n",
    "\n",
    "    # Merge scores on job_link\n",
    "    merged_scores = pd.merge(\n",
    "        text_recs[[\"job_link\", \"combined_text_score\"]],\n",
    "        skills_recs[[\"job_link\", \"skills_score\"]],\n",
    "        on=\"job_link\",\n",
    "        how=\"outer\",\n",
    "    ).fillna(0.0)\n",
    "\n",
    "    # Compute hybrid score\n",
    "    merged_scores[\"hybrid_score\"] = (\n",
    "        alpha_text * merged_scores[\"combined_text_score\"]\n",
    "        + alpha_skills * merged_scores[\"skills_score\"]\n",
    "    )\n",
    "\n",
    "    # Join back job metadata\n",
    "    full = merged_scores.merge(df, on=\"job_link\", how=\"left\")\n",
    "\n",
    "    # Re-apply location / country filter similar to recommend()\n",
    "    city = query.get(\"city\")\n",
    "    country = query.get(\"country\")\n",
    "\n",
    "    mask_city = (full[\"job_location\"] == city) if city is not None and \"job_location\" in full.columns else False\n",
    "    mask_country = (full[\"search_country\"] == country) if country is not None and \"search_country\" in full.columns else False\n",
    "\n",
    "    filtered = full[mask_city | mask_country]\n",
    "    if not filtered.empty:\n",
    "        full = filtered\n",
    "\n",
    "    # Sort and attach original index from df\n",
    "    full = full.sort_values(\"hybrid_score\", ascending=False).head(top_k)\n",
    "\n",
    "    # Build mapping: job_link -> original index in df\n",
    "    index_map = (\n",
    "        df.reset_index()[[\"index\", \"job_link\"]]\n",
    "          .set_index(\"job_link\")[\"index\"]\n",
    "    )\n",
    "    full[\"orig_index\"] = full[\"job_link\"].map(index_map)\n",
    "\n",
    "    # For printing: use orig_index as DataFrame index\n",
    "    full_print = full.set_index(\"orig_index\").copy()\n",
    "\n",
    "    print(\"Hybrid recommendations (description + title/skills):\")\n",
    "    print_recommendations(\n",
    "        full_print,\n",
    "        columns=[\n",
    "            \"company\",\n",
    "            \"job_title\",\n",
    "            \"job_skills\",\n",
    "            \"job_location\",\n",
    "            \"hybrid_score\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # For returning: clean 0..n index, but keep orig_index as a column\n",
    "    return full.reset_index(drop=True)"
   ],
   "id": "4eb923a03b76bac7",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Example query:",
   "id": "a5800c6200d5768c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:57.420735Z",
     "start_time": "2025-11-30T21:49:57.174006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query without NLP features (except skills)\n",
    "query = {'city': 'New York', 'country': 'United States', 'title': 'Data Scientist', 'skills': ['python', 'machine learning', 'data analysis']}\n",
    "recommend(jobs_df, query, vectorizer, matrix, top_k=10)\n",
    "\n",
    "print()\n",
    "\n",
    "# Query with NLP features\n",
    "description_text = \"\"\"\n",
    "I am looking for a junior machine learning engineer position where I can build,\n",
    "train and deploy deep learning models in production. I enjoy working with\n",
    "Python, PyTorch, MLOps tools and scalable model pipelines. Ideally in a\n",
    "tech company with strong engineering culture.\n",
    "\"\"\"\n",
    "\n",
    "hybrid_recommend(\n",
    "    df=jobs_df,\n",
    "    query=query,\n",
    "    description_text=description_text,\n",
    "    vectorizer=vectorizer,\n",
    "    matrix=matrix,\n",
    "    text_rec=text_rec,\n",
    "    top_k=10,\n",
    "    alpha_text=0.6,\n",
    "    alpha_skills=0.4,\n",
    ")"
   ],
   "id": "7e7fd3ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended jobs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                 company  \\\n",
       "2887                                    X4 Life Sciences   \n",
       "2879                                                 257   \n",
       "3713   Tribal Tech - The Digital & Tech Recruitment S...   \n",
       "3335                                                 JBC   \n",
       "13200   Tribal Tech - The Digital, Data & AI Specialists   \n",
       "8528                                JPMorgan Chase & Co.   \n",
       "12201                                   X4 Life Sciences   \n",
       "5069                                               Arena   \n",
       "5068                                           Genentech   \n",
       "14300                                                RWE   \n",
       "\n",
       "                                         job_title  \\\n",
       "2887   senior/principal machine learning scientist   \n",
       "2879                                data scientist   \n",
       "3713             machine learning / data scientist   \n",
       "3335                          staff data scientist   \n",
       "13200            machine learning / data scientist   \n",
       "8528                    machine learning scientist   \n",
       "12201         principal machine learning scientist   \n",
       "5069                    machine learning scientist   \n",
       "5068                    machine learning scientist   \n",
       "14300          energy trading data scientist m/f/t   \n",
       "\n",
       "                                              job_skills job_location  \n",
       "2887   collaboration, data preprocessing, machine lea...     New York  \n",
       "2879   algorithms, big data, data analysis, data engi...     New York  \n",
       "3713   clustering, collaboration, communication, comp...     New York  \n",
       "3335   clustering, collaboration skills, communicatio...     New York  \n",
       "13200  clustering, collaboration, communication, comp...     New York  \n",
       "8528   big data, data science, deep learning, machine...     New York  \n",
       "12201  collaboration, communication, data preprocessi...     New York  \n",
       "5069   analytical skills, communication skills, data ...     New York  \n",
       "5068   aws, azure, data analysis, devops, gcp, git, l...     New York  \n",
       "14300  applied mathematics, attention to detail, comm...     New York  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>senior/principal machine learning scientist</td>\n",
       "      <td>collaboration, data preprocessing, machine lea...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>257</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>algorithms, big data, data analysis, data engi...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>Tribal Tech - The Digital &amp; Tech Recruitment S...</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>JBC</td>\n",
       "      <td>staff data scientist</td>\n",
       "      <td>clustering, collaboration skills, communicatio...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13200</th>\n",
       "      <td>Tribal Tech - The Digital, Data &amp; AI Specialists</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>big data, data science, deep learning, machine...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12201</th>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>principal machine learning scientist</td>\n",
       "      <td>collaboration, communication, data preprocessi...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>Arena</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>analytical skills, communication skills, data ...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>Genentech</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>aws, azure, data analysis, devops, gcp, git, l...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14300</th>\n",
       "      <td>RWE</td>\n",
       "      <td>energy trading data scientist m/f/t</td>\n",
       "      <td>applied mathematics, attention to detail, comm...</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid recommendations (description + title/skills):\n",
      "Recommended jobs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                      company  \\\n",
       "orig_index                                                      \n",
       "2887                                         X4 Life Sciences   \n",
       "12201                                        X4 Life Sciences   \n",
       "3713        Tribal Tech - The Digital & Tech Recruitment S...   \n",
       "13200        Tribal Tech - The Digital, Data & AI Specialists   \n",
       "5069                                                    Arena   \n",
       "8528                                     JPMorgan Chase & Co.   \n",
       "6818                                       Algo Capital Group   \n",
       "3335                                                      JBC   \n",
       "2787                                    Hexaware Technologies   \n",
       "5068                                                Genentech   \n",
       "\n",
       "                                              job_title  \\\n",
       "orig_index                                                \n",
       "2887        senior/principal machine learning scientist   \n",
       "12201              principal machine learning scientist   \n",
       "3713                  machine learning / data scientist   \n",
       "13200                 machine learning / data scientist   \n",
       "5069                         machine learning scientist   \n",
       "8528                         machine learning scientist   \n",
       "6818              machine learning engineer c++/ python   \n",
       "3335                               staff data scientist   \n",
       "2787                     lead machine learning engineer   \n",
       "5068                         machine learning scientist   \n",
       "\n",
       "                                                   job_skills job_location  \\\n",
       "orig_index                                                                   \n",
       "2887        collaboration, data preprocessing, machine lea...     New York   \n",
       "12201       collaboration, communication, data preprocessi...     New York   \n",
       "3713        clustering, collaboration, communication, comp...     New York   \n",
       "13200       clustering, collaboration, communication, comp...     New York   \n",
       "5069        analytical skills, communication skills, data ...     New York   \n",
       "8528        big data, data science, deep learning, machine...     New York   \n",
       "6818        algorithms, analytical skills, c, communicatio...     New York   \n",
       "3335        clustering, collaboration skills, communicatio...     New York   \n",
       "2787        agile, deep learning, educational technology, ...     New York   \n",
       "5068        aws, azure, data analysis, devops, gcp, git, l...     New York   \n",
       "\n",
       "            hybrid_score  \n",
       "orig_index                \n",
       "2887            0.875349  \n",
       "12201           0.830240  \n",
       "3713            0.798307  \n",
       "13200           0.785765  \n",
       "5069            0.770405  \n",
       "8528            0.763374  \n",
       "6818            0.756973  \n",
       "3335            0.741100  \n",
       "2787            0.733918  \n",
       "5068            0.716075  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_location</th>\n",
       "      <th>hybrid_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orig_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>senior/principal machine learning scientist</td>\n",
       "      <td>collaboration, data preprocessing, machine lea...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.875349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12201</th>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>principal machine learning scientist</td>\n",
       "      <td>collaboration, communication, data preprocessi...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.830240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3713</th>\n",
       "      <td>Tribal Tech - The Digital &amp; Tech Recruitment S...</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.798307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13200</th>\n",
       "      <td>Tribal Tech - The Digital, Data &amp; AI Specialists</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.785765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>Arena</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>analytical skills, communication skills, data ...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.770405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8528</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>big data, data science, deep learning, machine...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.763374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>Algo Capital Group</td>\n",
       "      <td>machine learning engineer c++/ python</td>\n",
       "      <td>algorithms, analytical skills, c, communicatio...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.756973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>JBC</td>\n",
       "      <td>staff data scientist</td>\n",
       "      <td>clustering, collaboration skills, communicatio...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>lead machine learning engineer</td>\n",
       "      <td>agile, deep learning, educational technology, ...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.733918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5068</th>\n",
       "      <td>Genentech</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>aws, azure, data analysis, devops, gcp, git, l...</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.716075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                                            job_link  combined_text_score  \\\n",
       "0  https://www.linkedin.com/jobs/view/senior-prin...             0.896621   \n",
       "1  https://www.linkedin.com/jobs/view/principal-m...             0.895560   \n",
       "2  https://www.linkedin.com/jobs/view/machine-lea...             0.815857   \n",
       "3  https://www.linkedin.com/jobs/view/machine-lea...             0.817309   \n",
       "4  https://www.linkedin.com/jobs/view/machine-lea...             0.811007   \n",
       "5  https://www.linkedin.com/jobs/view/machine-lea...             0.780892   \n",
       "6  https://www.linkedin.com/jobs/view/machine-lea...             0.861407   \n",
       "7  https://www.linkedin.com/jobs/view/staff-data-...             0.728915   \n",
       "8  https://www.linkedin.com/jobs/view/lead-machin...             0.856341   \n",
       "9  https://www.linkedin.com/jobs/view/machine-lea...             0.736229   \n",
       "\n",
       "   skills_score  hybrid_score                                    job_title  \\\n",
       "0      0.843442      0.875349  senior/principal machine learning scientist   \n",
       "1      0.732260      0.830240         principal machine learning scientist   \n",
       "2      0.771982      0.798307            machine learning / data scientist   \n",
       "3      0.738449      0.785765            machine learning / data scientist   \n",
       "4      0.709502      0.770405                   machine learning scientist   \n",
       "5      0.737097      0.763374                   machine learning scientist   \n",
       "6      0.600323      0.756973        machine learning engineer c++/ python   \n",
       "7      0.759377      0.741100                         staff data scientist   \n",
       "8      0.550284      0.733918               lead machine learning engineer   \n",
       "9      0.685845      0.716075                   machine learning scientist   \n",
       "\n",
       "  job_location search_country  \\\n",
       "0     New York  United States   \n",
       "1     New York  United States   \n",
       "2     New York  United States   \n",
       "3     New York  United States   \n",
       "4     New York  United States   \n",
       "5     New York  United States   \n",
       "6     New York  United States   \n",
       "7     New York  United States   \n",
       "8     New York  United States   \n",
       "9     New York  United States   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0  collaboration, data preprocessing, machine lea...   \n",
       "1  collaboration, communication, data preprocessi...   \n",
       "2  clustering, collaboration, communication, comp...   \n",
       "3  clustering, collaboration, communication, comp...   \n",
       "4  analytical skills, communication skills, data ...   \n",
       "5  big data, data science, deep learning, machine...   \n",
       "6  algorithms, analytical skills, c, communicatio...   \n",
       "7  clustering, collaboration skills, communicatio...   \n",
       "8  agile, deep learning, educational technology, ...   \n",
       "9  aws, azure, data analysis, devops, gcp, git, l...   \n",
       "\n",
       "                                             company  \\\n",
       "0                                   X4 Life Sciences   \n",
       "1                                   X4 Life Sciences   \n",
       "2  Tribal Tech - The Digital & Tech Recruitment S...   \n",
       "3   Tribal Tech - The Digital, Data & AI Specialists   \n",
       "4                                              Arena   \n",
       "5                               JPMorgan Chase & Co.   \n",
       "6                                 Algo Capital Group   \n",
       "7                                                JBC   \n",
       "8                              Hexaware Technologies   \n",
       "9                                          Genentech   \n",
       "\n",
       "                  search_position  \\\n",
       "0  Agricultural-Research Engineer   \n",
       "1                      Biochemist   \n",
       "2    Electrical-Research Engineer   \n",
       "3                      Biochemist   \n",
       "4  Agricultural-Research Engineer   \n",
       "5                  Horticulturist   \n",
       "6  Agricultural-Research Engineer   \n",
       "7                         Chemist   \n",
       "8     Data Communications Analyst   \n",
       "9  Agricultural-Research Engineer   \n",
       "\n",
       "                                         job_summary   job_level  \\\n",
       "0  My client is a leading firm at the intersectio...  Mid senior   \n",
       "1  My client is a leading firm at the intersectio...  Mid senior   \n",
       "2  Location: New York\\nPosition Type: Full-Time\\n...  Mid senior   \n",
       "3  Location: New York\\nPosition Type: Full-Time\\n...  Mid senior   \n",
       "4  Who we are:\\nOur name is inspired by Theodore ...  Mid senior   \n",
       "5  Job Description\\nApplied AI ML opportunities a...  Mid senior   \n",
       "6  My client is a world-class quantitative invest...  Mid senior   \n",
       "7  Location: Long Island City, New York\\nType: Pe...   Associate   \n",
       "8  HIR ING\\nJob Skills\\nTensorFlow, TensorFlow, B...  Mid senior   \n",
       "9  The Position\\nThe Opportunity\\nThe Large Molec...   Associate   \n",
       "\n",
       "                                        title_skills  orig_index  \n",
       "0  senior/principal machine learning scientist co...        2887  \n",
       "1  principal machine learning scientist collabora...       12201  \n",
       "2  machine learning / data scientist clustering, ...        3713  \n",
       "3  machine learning / data scientist clustering, ...       13200  \n",
       "4  machine learning scientist analytical skills, ...        5069  \n",
       "5  machine learning scientist big data, data scie...        8528  \n",
       "6  machine learning engineer c++/ python algorith...        6818  \n",
       "7  staff data scientist clustering, collaboration...        3335  \n",
       "8  lead machine learning engineer agile, deep lea...        2787  \n",
       "9  machine learning scientist aws, azure, data an...        5068  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>combined_text_score</th>\n",
       "      <th>skills_score</th>\n",
       "      <th>hybrid_score</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>search_country</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>company</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_summary</th>\n",
       "      <th>job_level</th>\n",
       "      <th>title_skills</th>\n",
       "      <th>orig_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-prin...</td>\n",
       "      <td>0.896621</td>\n",
       "      <td>0.843442</td>\n",
       "      <td>0.875349</td>\n",
       "      <td>senior/principal machine learning scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>collaboration, data preprocessing, machine lea...</td>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>My client is a leading firm at the intersectio...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>senior/principal machine learning scientist co...</td>\n",
       "      <td>2887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/principal-m...</td>\n",
       "      <td>0.895560</td>\n",
       "      <td>0.732260</td>\n",
       "      <td>0.830240</td>\n",
       "      <td>principal machine learning scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>collaboration, communication, data preprocessi...</td>\n",
       "      <td>X4 Life Sciences</td>\n",
       "      <td>Biochemist</td>\n",
       "      <td>My client is a leading firm at the intersectio...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>principal machine learning scientist collabora...</td>\n",
       "      <td>12201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.815857</td>\n",
       "      <td>0.771982</td>\n",
       "      <td>0.798307</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>Tribal Tech - The Digital &amp; Tech Recruitment S...</td>\n",
       "      <td>Electrical-Research Engineer</td>\n",
       "      <td>Location: New York\\nPosition Type: Full-Time\\n...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>machine learning / data scientist clustering, ...</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.817309</td>\n",
       "      <td>0.738449</td>\n",
       "      <td>0.785765</td>\n",
       "      <td>machine learning / data scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>clustering, collaboration, communication, comp...</td>\n",
       "      <td>Tribal Tech - The Digital, Data &amp; AI Specialists</td>\n",
       "      <td>Biochemist</td>\n",
       "      <td>Location: New York\\nPosition Type: Full-Time\\n...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>machine learning / data scientist clustering, ...</td>\n",
       "      <td>13200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>0.709502</td>\n",
       "      <td>0.770405</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>analytical skills, communication skills, data ...</td>\n",
       "      <td>Arena</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Who we are:\\nOur name is inspired by Theodore ...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>machine learning scientist analytical skills, ...</td>\n",
       "      <td>5069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.780892</td>\n",
       "      <td>0.737097</td>\n",
       "      <td>0.763374</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>big data, data science, deep learning, machine...</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>Horticulturist</td>\n",
       "      <td>Job Description\\nApplied AI ML opportunities a...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>machine learning scientist big data, data scie...</td>\n",
       "      <td>8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.861407</td>\n",
       "      <td>0.600323</td>\n",
       "      <td>0.756973</td>\n",
       "      <td>machine learning engineer c++/ python</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>algorithms, analytical skills, c, communicatio...</td>\n",
       "      <td>Algo Capital Group</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>My client is a world-class quantitative invest...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>machine learning engineer c++/ python algorith...</td>\n",
       "      <td>6818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/staff-data-...</td>\n",
       "      <td>0.728915</td>\n",
       "      <td>0.759377</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>staff data scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>clustering, collaboration skills, communicatio...</td>\n",
       "      <td>JBC</td>\n",
       "      <td>Chemist</td>\n",
       "      <td>Location: Long Island City, New York\\nType: Pe...</td>\n",
       "      <td>Associate</td>\n",
       "      <td>staff data scientist clustering, collaboration...</td>\n",
       "      <td>3335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-machin...</td>\n",
       "      <td>0.856341</td>\n",
       "      <td>0.550284</td>\n",
       "      <td>0.733918</td>\n",
       "      <td>lead machine learning engineer</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>agile, deep learning, educational technology, ...</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>Data Communications Analyst</td>\n",
       "      <td>HIR ING\\nJob Skills\\nTensorFlow, TensorFlow, B...</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>lead machine learning engineer agile, deep lea...</td>\n",
       "      <td>2787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>0.736229</td>\n",
       "      <td>0.685845</td>\n",
       "      <td>0.716075</td>\n",
       "      <td>machine learning scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States</td>\n",
       "      <td>aws, azure, data analysis, devops, gcp, git, l...</td>\n",
       "      <td>Genentech</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>The Position\\nThe Opportunity\\nThe Large Molec...</td>\n",
       "      <td>Associate</td>\n",
       "      <td>machine learning scientist aws, azure, data an...</td>\n",
       "      <td>5068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "0f8cd106",
   "metadata": {},
   "source": [
    "# Association Rules\n",
    "\n",
    "In addition to recommending jobs based on similarity, we can suggest complementary skills using association rules. By analyzing which skills frequently appear together across job posts, we can discover patterns such as ‚Äúusers with skill A often also have skill B.‚Äù This allows the system to recommend additional skills a user might consider learning to improve their job prospects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b6cfd",
   "metadata": {},
   "source": [
    "## A-Priori Algorithm\n",
    "We use the Apriori algorithm to identify frequent sets of skills in the dataset. Apriori scans the job posts to find combinations of skills that occur together above a minimum support threshold. From these frequent itemsets, we generate association rules that describe patterns such as ‚Äúif a job requires skill A and B, it often also requires skill C.‚Äù These rules can then be used to recommend additional skills to a user."
   ]
  },
  {
   "cell_type": "code",
   "id": "4ee9d3db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:58.610781Z",
     "start_time": "2025-11-30T21:49:58.601135Z"
    }
   },
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "4ea0c3d6",
   "metadata": {},
   "source": [
    "We use the Apriori algorithm to discover frequently co-occurring skills in job posts. By setting a minimum support of 0.005, we only consider skill combinations that appear in at least 0.5% of the dataset. From these frequent itemsets, we generate association rules with a minimum confidence of 0.5.\n",
    "\n",
    "These rules allow the system to recommend complementary skills: given a user‚Äôs existing skills, the algorithm suggests additional skills that often appear together in job posts."
   ]
  },
  {
   "cell_type": "code",
   "id": "2360a175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:49:58.625461Z",
     "start_time": "2025-11-30T21:49:58.624257Z"
    }
   },
   "source": [
    "min_support=0.005\n",
    "min_threshold=0.5"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "cf8758ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:50:06.497345Z",
     "start_time": "2025-11-30T21:49:58.645981Z"
    }
   },
   "source": [
    "def compute_frequent_itemsets(df, min_support, min_threshold=0.5):\n",
    "        transactions = df['job_skills'].apply(lambda x: [s.strip() for s in x.split(',')]).tolist()\n",
    "        te = TransactionEncoder()\n",
    "        te_ary = te.fit(transactions).transform(transactions)\n",
    "        df_onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "        \n",
    "        frequent_itemsets = apriori(df_onehot, min_support=min_support, use_colnames=True)\n",
    "        rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_threshold)\n",
    "        return rules\n",
    "rules = compute_frequent_itemsets(jobs_df,min_support, min_threshold)"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "e321533c",
   "metadata": {},
   "source": [
    "### Recommending Additional Skills\n",
    "\n",
    "Given a user‚Äôs current skills, we can filter the association rules to find consequents that complement their skill set. The top recommendations are sorted by confidence or lift."
   ]
  },
  {
   "cell_type": "code",
   "id": "eedce0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-30T21:50:07.631572Z",
     "start_time": "2025-11-30T21:50:07.628309Z"
    }
   },
   "source": [
    "def recommend_skills(rules, user_skills, top_n=5, sort_by='confidence'):\n",
    "        # Filter rules where antecedents are subset of user_skills\n",
    "        matching_rules = rules[rules['antecedents'].apply(lambda x: set(x).issubset(user_skills))]\n",
    "        \n",
    "        # Collect consequents\n",
    "        recommended_skills = set()\n",
    "        for cons in matching_rules['consequents']:\n",
    "            recommended_skills.update(cons)\n",
    "        \n",
    "        # Remove skills user already has\n",
    "        recommended_skills = recommended_skills - set(user_skills)\n",
    "        \n",
    "        # Optionally, sort by confidence or lift\n",
    "        if not matching_rules.empty:\n",
    "            sorted_rules = matching_rules.sort_values(by=sort_by, ascending=False)\n",
    "            recommended_skills_ordered = []\n",
    "            for cons in sorted_rules['consequents']:\n",
    "                for skill in cons:\n",
    "                    if skill in recommended_skills and skill not in recommended_skills_ordered:\n",
    "                        recommended_skills_ordered.append(skill)\n",
    "            return recommended_skills_ordered[:top_n]\n",
    "        \n",
    "        return list(recommended_skills)[:top_n]\n",
    "\n",
    "recommended_skills = recommend_skills(rules, query['skills'], top_n=5)\n",
    "print(\"Recommended additional skills:\", recommended_skills)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended additional skills: ['sql']\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
